# LLM Output Logging - Implementation Summary

## Status: âœ… COMPLETE & ENABLED

Detailed logging has been added to show the full LLM interaction flow. You'll now see the prompts sent, raw responses received, and parsed results in the console/logs.

## What You'll See in the Logs

### 1. **Brain.swift** (Main Categorization)

When categorizing files, you'll see three sections:

#### ğŸ”µ PROMPT TO LLM
Shows what's being sent to the LLM:
```
ğŸ”µ [Brain] ===== PROMPT TO LLM =====
ğŸ”µ [Brain] Model: llama3.2
ğŸ”µ [Brain] Temperature: 0.3
ğŸ”µ [Brain] Max Tokens: 1000
ğŸ”µ [Brain] --- Prompt Start ---
You are a file categorization assistant. Your job is to categorize files into a HIERARCHICAL category system.

CATEGORY FORMAT: Use "/" to separate hierarchy levels. Examples:
- "Education / Programming / Python"
- "Entertainment / Magic / Card Tricks"
...

FILE TO CATEGORIZE:
Name: my_video.mp4
Type: video
Duration: 5:23
Visual themes: indoors, person, talking, presentation
Content preview: This is a tutorial about...

Return ONLY valid JSON in this format:
{
  "categoryPath": "Main / Sub1 / Sub2",
  "confidence": 0.85,
  "rationale": "Brief explanation",
  "keywords": ["relevant", "keywords"]
}
ğŸ”µ [Brain] --- Prompt End ---
```

#### ğŸŸ¢ RAW LLM RESPONSE
Shows the raw JSON response from the LLM:
```
ğŸŸ¢ [Brain] ===== RAW LLM RESPONSE =====
ğŸŸ¢ [Brain] Duration: 2.34s
ğŸŸ¢ [Brain] Response Length: 245 chars
ğŸŸ¢ [Brain] Prompt Tokens: 342
ğŸŸ¢ [Brain] Completion Tokens: 87
ğŸŸ¢ [Brain] --- Response Start ---
{
  "categoryPath": "Education / Programming / Python",
  "confidence": 0.92,
  "rationale": "The file appears to be a tutorial about Python programming based on the visual themes and content preview",
  "keywords": ["tutorial", "python", "programming", "education"]
}
ğŸŸ¢ [Brain] --- Response End ---
```

#### ğŸŸ£ PARSED RESULT
Shows how the response was interpreted:
```
ğŸŸ£ [Brain] ===== PARSED RESULT =====
ğŸŸ£ [Brain] Category Path: Education / Programming / Python
ğŸŸ£ [Brain] Confidence: 0.92
ğŸŸ£ [Brain] Rationale: The file appears to be a tutorial about Python programming based on the visual themes and content preview
ğŸŸ£ [Brain] Keywords: tutorial, python, programming, education
ğŸŸ£ [Brain] Graph Suggested: false
```

### 2. **OllamaProvider.swift** (Provider Level)

The OllamaProvider already had excellent logging:

#### ğŸ“¤ PROMPT Section
```
ğŸ“¤ [OllamaProvider] ====== PROMPT (1234 chars) ======

========== OLLAMA PROMPT START ==========
[Full prompt text here]
========== OLLAMA PROMPT END ==========
```

#### ğŸ“¥ RESPONSE Section
```
ğŸ“¥ [OllamaProvider] Response received in 2.45s - data size: 1024 bytes
ğŸ“Š [OllamaProvider] HTTP Status: 200
ğŸ“¥ [OllamaProvider] ====== RESPONSE (245 chars) ======

========== OLLAMA RESPONSE START ==========
{
  "categoryPath": "Education / Programming / Python",
  "confidence": 0.92,
  ...
}
========== OLLAMA RESPONSE END ==========

ğŸ“Š Ollama Stats: 2.34s, 342 prompt tokens, 87 completion tokens
```

### 3. **Error Cases**

When JSON parsing fails:
```
âŒ [Brain] JSON parsing failed: The data couldn't be read because it isn't in the correct format
âŒ [Brain] Cleaned response was: {"invalid json here...
```

When categories are blocked:
```
âš ï¸ [Brain] Blocked inappropriate category 'Adult / Explicit' - replacing with Uncategorized
```

## Where to View Logs

### Option 1: Xcode Console
- Run the app from Xcode
- Open the Debug Console (Cmd+Shift+Y)
- All `NSLog` statements appear here

### Option 2: macOS Console App
- Open `/Applications/Utilities/Console.app`
- Filter by process name: `SortAI`
- All logs appear here including from released builds

### Option 3: Terminal (for running directly)
```bash
./build/SortAI 2>&1 | grep -E "Brain|Ollama"
```

### Option 4: Log File (if you add file logging)
You could redirect logs to a file:
```bash
./build/SortAI 2>&1 | tee sortai_llm_output.log
```

## Log Filtering Tips

### See only LLM interactions:
```bash
# In Console.app, filter by:
subsystem:com.apple.console AND (
  message CONTAINS "Brain" OR 
  message CONTAINS "Ollama" OR 
  message CONTAINS "PROMPT" OR 
  message CONTAINS "RESPONSE"
)
```

### See only prompts:
```bash
grep "PROMPT" sortai.log
```

### See only responses:
```bash
grep "RESPONSE" sortai.log
```

### See only parsed results:
```bash
grep "PARSED RESULT" sortai.log
```

## Log Levels

The logging uses emoji prefixes for easy scanning:

- ğŸ”µ **Prompt** - What's being sent to the LLM
- ğŸŸ¢ **Response** - Raw response from the LLM  
- ğŸŸ£ **Parsed** - How the response was interpreted
- ğŸ“¤ **Outgoing** - Provider-level outgoing request
- ğŸ“¥ **Incoming** - Provider-level incoming response
- ğŸ“Š **Stats** - Token counts and performance metrics
- âš ï¸ **Warning** - Issues or fallbacks
- âŒ **Error** - Failures

## Performance Impact

The logging has minimal performance impact:
- **Prompt logging**: ~1ms (String formatting)
- **Response logging**: ~1ms (String formatting)
- **NSLog overhead**: ~0.1ms per call

Total overhead: **~5-10ms per LLM call** (negligible compared to 1-3s LLM response time)

## Disabling Logging (if needed)

If you want to disable this verbose logging in production:

### Option 1: Conditional Compilation
Wrap the NSLog calls in `#if DEBUG`:

```swift
#if DEBUG
NSLog("ğŸ”µ [Brain] ===== PROMPT TO LLM =====")
// ... logging code ...
#endif
```

### Option 2: Configuration Flag
Add to `AppConfiguration.swift`:

```swift
struct LoggingConfiguration: Codable, Sendable {
    var enableLLMPromptLogging: Bool = true
    var enableLLMResponseLogging: Bool = true
}
```

Then conditionally log:
```swift
if config.logging.enableLLMPromptLogging {
    NSLog("ğŸ”µ [Brain] ===== PROMPT TO LLM =====")
}
```

### Option 3: Log Level Filter
Use OS log levels and filter in Console.app:
```swift
import os.log

let logger = Logger(subsystem: "com.sortai.llm", category: "brain")
logger.debug("ğŸ”µ [Brain] ===== PROMPT TO LLM =====")  // Only in debug builds
```

## Example Output

Here's what a complete categorization looks like in the logs:

```
ğŸ‘ï¸ [MediaInspector] Starting inspection: tutorial_python.mp4
ğŸ¬ [MediaInspector] Video inspection started: tutorial_python.mp4
ğŸ¬ [MediaInspector] Metadata loaded in 0.123s - duration: 323.5s, hasAudio: true
ğŸ¬ [MediaInspector] Starting parallel extraction (frames + audio + subtitles)...
ğŸ¤ [MediaInspector] Starting multi-clip audio extraction for: tutorial_python.mp4
ğŸ“ [MultiClipExtractor] Long video (323.5s): 5 clips, total 225.0s
   Clip 0: 0.0s - 45.0s (45.0s)
   Clip 1: 80.9s - 125.9s (45.0s)
   Clip 2: 161.8s - 206.8s (45.0s)
   Clip 3: 242.6s - 287.6s (45.0s)
   Clip 4: 263.5s - 308.5s (45.0s)
ğŸ”µ [Brain] ===== PROMPT TO LLM =====
ğŸ”µ [Brain] Model: llama3.2
ğŸ”µ [Brain] Temperature: 0.3
ğŸ”µ [Brain] --- Prompt Start ---
You are a file categorization assistant...
FILE TO CATEGORIZE:
Name: tutorial_python.mp4
Type: video
Duration: 5:23
Visual themes: programming, code, terminal, typing
Content preview: In this video we'll learn about Python decorators...
ğŸ”µ [Brain] --- Prompt End ---
ğŸŸ¢ [Brain] ===== RAW LLM RESPONSE =====
ğŸŸ¢ [Brain] Duration: 2.34s
ğŸŸ¢ [Brain] Response Length: 245 chars
ğŸŸ¢ [Brain] Prompt Tokens: 342
ğŸŸ¢ [Brain] Completion Tokens: 87
ğŸŸ¢ [Brain] --- Response Start ---
{
  "categoryPath": "Education / Programming / Python / Advanced",
  "confidence": 0.95,
  "rationale": "Clear programming tutorial focused on Python decorators, an advanced topic",
  "keywords": ["python", "decorators", "tutorial", "programming", "advanced"]
}
ğŸŸ¢ [Brain] --- Response End ---
ğŸŸ£ [Brain] ===== PARSED RESULT =====
ğŸŸ£ [Brain] Category Path: Education / Programming / Python / Advanced
ğŸŸ£ [Brain] Confidence: 0.95
ğŸŸ£ [Brain] Rationale: Clear programming tutorial focused on Python decorators, an advanced topic
ğŸŸ£ [Brain] Keywords: python, decorators, tutorial, programming, advanced
ğŸŸ£ [Brain] Graph Suggested: false
âœ… [MediaInspector] Inspection complete: tutorial_python.mp4 in 5.67s
```

## Troubleshooting

### "I don't see any logs"
- Make sure you're running in Debug mode in Xcode
- Check Console.app and filter by "SortAI"
- Try running from terminal to see all output

### "Logs are too verbose"
- Use grep to filter: `grep "PARSED RESULT" sortai.log`
- Disable prompt/response logging (see "Disabling Logging" above)
- Use Console.app filters

### "Logs show garbled JSON"
- This means the LLM returned invalid JSON
- Check the RAW RESPONSE section to see what was returned
- The app should handle this gracefully and show a parsing error

## Future Enhancements

Possible additions:
1. **Log to file** - Automatically save all LLM interactions to `~/.sortai/llm_logs/`
2. **UI display** - Show recent LLM interactions in a debug panel
3. **JSON diff** - Show what changed when re-categorizing files
4. **Prompt templates** - Save/load different prompt templates for testing
5. **Response replay** - Cache responses for testing without hitting LLM

---

**Implementation Date**: January 5, 2026  
**Build Status**: âœ… Success  
**Log Locations**: Xcode Console, Console.app, Terminal stdout

